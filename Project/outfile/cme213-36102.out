The master node of this job is gpu-202-2
This job runs on the following nodes:
gpu-202-2
Starting at Sun Jun 10 17:37:11 PDT 2018
Running on hosts: gpu-202-2
Running on 1 nodes.
Running on 24 processors.
Current working directory is /home/czhang94/project

Output from code
----------------
++--------------------++
++      Case 1        ++
++--------------------++
Number of MPI processes = 4
Number of CUDA devices = 4
num_neuron=100, reg=0.0001, learning_rate=0.001, num_epochs=40, batch_size=800
Loading training data...
Training data stats...
Size of x_train, N =  60000
Size of label_train = 60000
Start Sequential Training
Time for Sequential Training: 126.701 seconds
Precision on validation set for sequential training = 0.894333

Start Parallel Training
Time for Parallel Training: 16.9173 seconds
Precision on validation set for parallel training = 0.894333

Grading mode on. Checking for correctness


max norm of diff b/w seq and par: W[0]: 1.24881e-15, b[0]: 3.53874e-15
l2  norm of diff b/w seq and par: W[0]: 1.12441e-15, b[0]: 1.97203e-15

max norm of diff b/w seq and par: W[1]: 4.39416e-16, b[1]: 9.19953e-16
l2  norm of diff b/w seq and par: W[1]: 7.7821e-16, b[1]: 6.58944e-16

++--------------------++
++      Case 2        ++
++--------------------++
Number of MPI processes = 4
Number of CUDA devices = 4
num_neuron=100, reg=0.0001, learning_rate=0.01, num_epochs=10, batch_size=800
Loading training data...
Training data stats...
Size of x_train, N =  60000
Size of label_train = 60000
Start Sequential Training
Time for Sequential Training: 31.7387 seconds
Precision on validation set for sequential training = 0.924167

Start Parallel Training
Time for Parallel Training: 4.71097 seconds
Precision on validation set for parallel training = 0.924167

Grading mode on. Checking for correctness


max norm of diff b/w seq and par: W[0]: 4.53111e-09, b[0]: 6.10204e-09
l2  norm of diff b/w seq and par: W[0]: 3.52465e-09, b[0]: 2.03158e-09

max norm of diff b/w seq and par: W[1]: 2.88588e-11, b[1]: 2.28154e-10
l2  norm of diff b/w seq and par: W[1]: 5.07357e-11, b[1]: 1.93486e-10

++--------------------++
++      Case 3        ++
++--------------------++
Number of MPI processes = 4
Number of CUDA devices = 4
num_neuron=100, reg=0.0001, learning_rate=0.025, num_epochs=1, batch_size=800
Loading training data...
Training data stats...
Size of x_train, N =  60000
Size of label_train = 60000
Start Sequential Training
Loss at iteration 0 of epoch 0/1 = 2.31287
Loss at iteration 1 of epoch 0/1 = 2.29801
Loss at iteration 2 of epoch 0/1 = 2.28377
Loss at iteration 3 of epoch 0/1 = 2.26285
Loss at iteration 4 of epoch 0/1 = 2.24996
Loss at iteration 5 of epoch 0/1 = 2.23732
Loss at iteration 6 of epoch 0/1 = 2.21529
Loss at iteration 7 of epoch 0/1 = 2.20254
Loss at iteration 8 of epoch 0/1 = 2.18886
Loss at iteration 9 of epoch 0/1 = 2.18379
Loss at iteration 10 of epoch 0/1 = 2.1622
Loss at iteration 11 of epoch 0/1 = 2.14225
Loss at iteration 12 of epoch 0/1 = 2.11962
Loss at iteration 13 of epoch 0/1 = 2.11017
Loss at iteration 14 of epoch 0/1 = 2.09901
Loss at iteration 15 of epoch 0/1 = 2.08981
Loss at iteration 16 of epoch 0/1 = 2.07929
Loss at iteration 17 of epoch 0/1 = 2.07228
Loss at iteration 18 of epoch 0/1 = 2.0566
Loss at iteration 19 of epoch 0/1 = 2.02486
Loss at iteration 20 of epoch 0/1 = 2.00348
Loss at iteration 21 of epoch 0/1 = 2.00874
Loss at iteration 22 of epoch 0/1 = 1.9786
Loss at iteration 23 of epoch 0/1 = 1.95694
Loss at iteration 24 of epoch 0/1 = 1.93332
Loss at iteration 25 of epoch 0/1 = 1.92866
Loss at iteration 26 of epoch 0/1 = 1.90449
Loss at iteration 27 of epoch 0/1 = 1.88565
Loss at iteration 28 of epoch 0/1 = 1.88499
Loss at iteration 29 of epoch 0/1 = 1.8643
Loss at iteration 30 of epoch 0/1 = 1.85119
Loss at iteration 31 of epoch 0/1 = 1.80484
Loss at iteration 32 of epoch 0/1 = 1.79455
Loss at iteration 33 of epoch 0/1 = 1.80235
Loss at iteration 34 of epoch 0/1 = 1.77634
Loss at iteration 35 of epoch 0/1 = 1.74506
Loss at iteration 36 of epoch 0/1 = 1.73507
Loss at iteration 37 of epoch 0/1 = 1.7554
Loss at iteration 38 of epoch 0/1 = 1.72471
Loss at iteration 39 of epoch 0/1 = 1.72265
Loss at iteration 40 of epoch 0/1 = 1.72514
Loss at iteration 41 of epoch 0/1 = 1.65438
Loss at iteration 42 of epoch 0/1 = 1.61837
Loss at iteration 43 of epoch 0/1 = 1.65605
Loss at iteration 44 of epoch 0/1 = 1.61038
Loss at iteration 45 of epoch 0/1 = 1.59497
Loss at iteration 46 of epoch 0/1 = 1.61504
Loss at iteration 47 of epoch 0/1 = 1.583
Loss at iteration 48 of epoch 0/1 = 1.52233
Loss at iteration 49 of epoch 0/1 = 1.57788
Loss at iteration 50 of epoch 0/1 = 1.51239
Loss at iteration 51 of epoch 0/1 = 1.53203
Loss at iteration 52 of epoch 0/1 = 1.49343
Loss at iteration 53 of epoch 0/1 = 1.49928
Loss at iteration 54 of epoch 0/1 = 1.46194
Loss at iteration 55 of epoch 0/1 = 1.46226
Loss at iteration 56 of epoch 0/1 = 1.46197
Loss at iteration 57 of epoch 0/1 = 1.45531
Loss at iteration 58 of epoch 0/1 = 1.39488
Loss at iteration 59 of epoch 0/1 = 1.42089
Loss at iteration 60 of epoch 0/1 = 1.36021
Loss at iteration 61 of epoch 0/1 = 1.42482
Loss at iteration 62 of epoch 0/1 = 1.39992
Loss at iteration 63 of epoch 0/1 = 1.35844
Loss at iteration 64 of epoch 0/1 = 1.33385
Loss at iteration 65 of epoch 0/1 = 1.32401
Loss at iteration 66 of epoch 0/1 = 1.33066
Loss at iteration 67 of epoch 0/1 = 1.31068
Time for Sequential Training: 9.5383 seconds
Precision on validation set for sequential training = 0.845167

Start Parallel Training
Time for Parallel Training: 8.94587 seconds
Precision on validation set for parallel training = 0.845167

Grading mode on. Checking for correctness


max norm of diff b/w seq and par: W[0]: 3.64473e-11, b[0]: 9.35092e-11
l2  norm of diff b/w seq and par: W[0]: 3.47669e-11, b[0]: 2.65104e-11

max norm of diff b/w seq and par: W[1]: 1.77114e-13, b[1]: 2.22729e-12
l2  norm of diff b/w seq and par: W[1]: 7.47798e-13, b[1]: 2.45754e-12

++--------------------++
++     Benchmark      ++
++--------------------++
Number of MPI processes = 4
Number of CUDA devices = 4
num_neuron=1000, reg=0.0001, learning_rate=0.001, num_epochs=20, batch_size=800
Loading training data...
Training data stats...
Size of x_train, N =  60000
Size of label_train = 60000

Start Parallel Training
Time for Parallel Training: 48.779 seconds
Precision on validation set for parallel training = 0.909667

++--------------------++
++      myGEMM        ++
++--------------------++
Number of MPI processes = 4
Number of CUDA devices = 4

Entering GEMM Benchmarking mode! Stand by.

Starting GEMM 1: M = 800; N = 1000; K = 784
GEMM matched with reference successfully! Rel diff = 0
Time for reference GEMM implementation: 0.0468681 seconds
Time for my GEMM implementation: 0.152773 seconds
Completed GEMM 1

Starting GEMM 2: M = 800; N = 10; K = 1000
GEMM matched with reference successfully! Rel diff = 0
Time for reference GEMM implementation: 0.00440423 seconds
Time for my GEMM implementation: 0.0065192 seconds
Completed GEMM 2

